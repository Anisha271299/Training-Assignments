{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Necessary Libraries**"
      ],
      "metadata": {
        "id": "up-r7HU6jgHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pandas** is used to analyze data.\n",
        "\n",
        "**Numpy** is used for working with arrays.\n",
        "\n",
        "**Re** is used to work with Regular Expressions\n",
        "\n",
        "**os** module is used to interact with the underlying operating system"
      ],
      "metadata": {
        "id": "HWEp034CkAdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "jFpCEWaojJZT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l6KAtHMjJZV"
      },
      "source": [
        "# **Importing the dataset using pandas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "udVAKxrVjJZX",
        "outputId": "eb3bd29d-b7de-4f66-8a06-24c7c8c7e101"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation\n",
              "5   6      0  [2/2] huge fan fare and big talking before the...\n",
              "6   7      0   @user camping tomorrow @user @user @user @use...\n",
              "7   8      0  the next school year is the year for exams.ð...\n",
              "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
              "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77b4bc30-9eb5-4717-b85f-34c32a1eb6e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>the next school year is the year for exams.ð...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77b4bc30-9eb5-4717-b85f-34c32a1eb6e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-77b4bc30-9eb5-4717-b85f-34c32a1eb6e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-77b4bc30-9eb5-4717-b85f-34c32a1eb6e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "inp_tweets0 = pd.read_csv(\"Tweets_USA.csv\")\n",
        "inp_tweets0.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting the number of tweets under labels 0 and 1"
      ],
      "metadata": {
        "id": "1tjL7-ASAXY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWaZwcQ6jJZY",
        "outputId": "574dc67e-e9c8-4d86-f2c1-d267d0295c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "inp_tweets0.label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus we have **29720** tweets under **label 0** and **2242** tweets under **label 1**. From this, we can observe that our data is highly imbalanced."
      ],
      "metadata": {
        "id": "V-ig6_eXAvkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's count after normalizing it!"
      ],
      "metadata": {
        "id": "mgLbJZZeAsP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp_tweets0.label.value_counts(normalize= True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9pBSaNNAQtd",
        "outputId": "02157f7b-caf6-402f-cb64-27fade4dcdb4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.929854\n",
              "1    0.070146\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus **92.9%** of the tweets are under **label 0** and only **7%** are under **label** **1**."
      ],
      "metadata": {
        "id": "EV6U4E0TBNZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing a sample tweet from the dataset"
      ],
      "metadata": {
        "id": "GgAnJrqX_4qq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SG9787WCjJZY",
        "outputId": "117f84e6-b162-4260-ce7b-69f6d228e7ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' @user @user @user @user beauties with broken heas .      ð\\x9f\\x9a£ð\\x9f\\x9a£ð\\x9f\\x9a£'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "inp_tweets0.tweet.sample().values[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe that the tweets contain soo many meaningless words, some special characters , punctuations etc.\n",
        "\n",
        "We have to clean these tweets in order to build the model."
      ],
      "metadata": {
        "id": "Gd8MK1pXBtZC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kphm47GxjJZZ"
      },
      "source": [
        "#**Converting the tweets into a list, for easy text clean up and manipulation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Qi1--XW6jJZZ"
      },
      "outputs": [],
      "source": [
        "tweets0 = inp_tweets0.tweet.values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the length of the list"
      ],
      "metadata": {
        "id": "yfGtreHSmDnq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "380tuJpojJZa",
        "outputId": "def6af93-dca7-448f-fd5a-43ca8494bd27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31962"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ],
      "source": [
        "len(tweets0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the first four tweets"
      ],
      "metadata": {
        "id": "40_a3tNomLba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yVWuwmBjJZa",
        "outputId": "0e89dd9f-2b6e-4207-f971-855709348e5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              "       \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              "       '  bihday your majesty',\n",
              "       '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
              "       ' factsguide: society now    #motivation'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "tweets0[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mADMDHkVjJZb"
      },
      "source": [
        "#**Cleaning up the Data**\n",
        "#**Normalizing case**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First lets normalize the case by converting all the words in the list to lowercase"
      ],
      "metadata": {
        "id": "8XoAwHAYm849"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "UJNy4Ah3jJZb"
      },
      "outputs": [],
      "source": [
        "tweets_lower = [twt.lower() for twt in tweets0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check whether all the texts are converted to lowercase by printing the first four tweets in the list"
      ],
      "metadata": {
        "id": "U9CqW32intM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMHxXXuTjJZb",
        "outputId": "48efe029-cc9f-4cd7-a50a-f1910fc63ba1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              " \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              " '  bihday your majesty',\n",
              " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
              " ' factsguide: society now    #motivation']"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "tweets_lower[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that all the words in our dataset is converted into lowercase"
      ],
      "metadata": {
        "id": "DfIcfEMSn3Dx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eizvgf_NjJZc"
      },
      "source": [
        "#**Remove user handles, begin with '@'**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's remove words begining with **\"@\"** using regular expression.\n",
        "\n",
        "Here, **sub()** function is used to replace occurrences of a particular sub-string with another sub-string.\n",
        "\n",
        "**\\w+** matches one or more word characters"
      ],
      "metadata": {
        "id": "pne4-WDcoJd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code removes all the words starting with '@'"
      ],
      "metadata": {
        "id": "Gbzg5Z7wC6aL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CX8OPYbAjJZd",
        "outputId": "4e965162-89f6-45b2-d54e-8b38a812cb69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' this course rocks! http://rahimbaig.com/ai'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "re.sub(\"@\\w+\",\"\", \"@Rahim this course rocks! http://rahimbaig.com/ai\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's remove all the words starting with '@' from the list using **for loop**"
      ],
      "metadata": {
        "id": "pLjWNPaCqjsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "6GjP7fLQjJZd"
      },
      "outputs": [],
      "source": [
        "tweets_nouser = [re.sub(\"@\\w+\",\"\",twt)for twt in tweets_lower]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check whether all the texts starting with '@' are removed by printing the first four tweets in the list"
      ],
      "metadata": {
        "id": "U5ZlZjrkrIYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR4q401FjJZd",
        "outputId": "fd86fdc8-568b-405a-eed2-195558266d56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              " '  bihday your majesty',\n",
              " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
              " ' factsguide: society now    #motivation']"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "tweets_nouser[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_UyKR5kjJZd"
      },
      "source": [
        "#**Remove URLs**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's remove all the URLs in the list since there is no use of those URLs .\n",
        "\n",
        "We can do this by adding **'://'** in the middle of the regex **'\\w+'** and **'\\S+'** so that it will remove all the words containing **'://'** in the middle."
      ],
      "metadata": {
        "id": "1GmI6HeKrjwY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zunvBoRWjJZd",
        "outputId": "5ee713c7-b4f8-4f3b-b191-93084cc81965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@Rahim this course rocks! '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "re.sub(\"\\w+://\\S+\",\"\", \"@Rahim this course rocks! http://rahimbaig.com/ai\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "yslxSfUpjJZe"
      },
      "outputs": [],
      "source": [
        "tweets_nour1 = [re.sub(\"\\w+://\\S+\",\"\",twt)for twt in tweets_nouser]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's check whether it removed all the URLs"
      ],
      "metadata": {
        "id": "wcr8zu_qtwZt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRDkxZlvjJZe",
        "outputId": "bc2bc1cc-a876-41e2-f4d5-7d36f3f14441"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
              " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
              " '  bihday your majesty',\n",
              " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
              " ' factsguide: society now    #motivation']"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "tweets_nour1[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaVWu-vRjJZe"
      },
      "source": [
        "#**Tokenize using tweet tokenizer from NLTK**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLTK has this special method called **TweetTokenizer**() that helps to tokenize Tweet Corpus into relevant tokens. The advantage of using TweetTokenizer() compared to regular word_tokenize is that, when processing tweets, we often come across emojis, hashtags that need to be handled differently."
      ],
      "metadata": {
        "id": "nIdQRIP6uJ-L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "saNCVlwIjJZe"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TweetTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "IfJUc2GWjJZf"
      },
      "outputs": [],
      "source": [
        "tkn = TweetTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnTVL5WHjJZf",
        "outputId": "01befc74-b01f-4b61-901b-07a1d2335be0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run']\n"
          ]
        }
      ],
      "source": [
        "print (tkn.tokenize(tweets_nour1[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's tokenize all the words in our cleaned data using for loop"
      ],
      "metadata": {
        "id": "7kJ8ceo7udCw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iKLDqrdjJZf",
        "outputId": "dc91e0b2-d7d1-4180-94be-4f9334a094e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run'], ['thanks', 'for', '#lyft', 'credit', 'i', \"can't\", 'use', 'cause', 'they', \"don't\", 'offer', 'wheelchair', 'vans', 'in', 'pdx', '.', '#disapointed', '#getthanked'], ['bihday', 'your', 'majesty'], ['#model', 'i', 'love', 'u', 'take', 'with', 'u', 'all', 'the', 'time', 'in', 'urð', '\\x9f', '\\x93', '±', '!', '!', '!', 'ð', '\\x9f', '\\x98', '\\x99', 'ð', '\\x9f', '\\x98', '\\x8e', 'ð', '\\x9f', '\\x91', '\\x84', 'ð', '\\x9f', '\\x91', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦', 'ð', '\\x9f', '\\x92', '¦'], ['factsguide', ':', 'society', 'now', '#motivation']]\n"
          ]
        }
      ],
      "source": [
        "tweet_token = [tkn.tokenize(sent)for sent in tweets_nour1]\n",
        "print(tweet_token[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can observe that all the sentences in our list is converted into words but still we have to do some more steps to get cleaned dataset for building the model. Let's do it now!\n"
      ],
      "metadata": {
        "id": "SZyc1QAQDicx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1A6VF0HjJZf"
      },
      "source": [
        "#**Remove punctuations and stop words and other redundant terms like 'rt', 'amp'**\n",
        "#**also remove hashtags**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stop words** are all those words that don't add much information to the sentence.In order to remove stopwords and punctuation using NLTK, we have to download all the stop words using nltk. download('stopwords'), then we have to specify the language for which we want to remove the stopwords, therefore, we use stopwords. words('english') to specify and save it to the variable.\n",
        "\n",
        "**Punctuation** can be removed by importing punctuation from string and then saving it as a list in a variable. Then we can define a function to remove all those unnecessary stopwards and punctuation from our data"
      ],
      "metadata": {
        "id": "t2JXmkRMvW5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "g_09zLzOxDhu"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLQEt5fZjJZg",
        "outputId": "d2470e15-6f52-451b-adbb-f3cf8dd87d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "AYEau1QLjJZg"
      },
      "outputs": [],
      "source": [
        "stop_nltk = stopwords.words(\"english\")\n",
        "stop_punct = list(punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's extend the list of Punctuation by adding the following expression since those expressions are also there in our data which adds no meaning to the sentance."
      ],
      "metadata": {
        "id": "Rv5PQbI7v-8Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "WzheiAKyjJZg"
      },
      "outputs": [],
      "source": [
        "stop_punct.extend(['...','``',\"''\",\"..\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's remove redundant words like 'rt' and 'amp' since there is no meaning in those words."
      ],
      "metadata": {
        "id": "fFw0wvDPwwrk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "o1N7-fstjJZg"
      },
      "outputs": [],
      "source": [
        "stop_context = ['rt', 'amp']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, lets finalize the words which we are going to remove from our list by adding stopwords and punctuations and redundant contexts."
      ],
      "metadata": {
        "id": "izOAEeG2yHER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "lOU5-IU3jJZh"
      },
      "outputs": [],
      "source": [
        "stop_final = stop_nltk + stop_punct + stop_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_T5rrasjJZh"
      },
      "source": [
        "#**Function to**\n",
        "- -> Remove stopwords from a single tokenized sentence\n",
        "- -> remove #tags\n",
        "- -> remove terms with length = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define a function to remove stopwords and punctuation using for loop and also giving condition to remove terms which are having length less than 1 .\n",
        "\n",
        "Also we are removing #tags from the term .\n",
        "\n",
        "Finally, we will be having a list of meaningful words."
      ],
      "metadata": {
        "id": "sMcUK5vUyjpc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "EOWXFi0ujJZh"
      },
      "outputs": [],
      "source": [
        "def del_stop(sent):\n",
        "    return [re.sub(\"#\",\"\",term) for term in sent if ((term not in stop_final) & (len(term)>1))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_N-kLxijJZh",
        "outputId": "73366428-7c44-439f-bbe7-a7ed606f9d28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['factsguide', 'society', 'motivation']"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ],
      "source": [
        "del_stop (tweet_token[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "w8EluaLmjJZh"
      },
      "outputs": [],
      "source": [
        "tweets_clean = [del_stop(tweet) for tweet in tweet_token]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tweets_clean[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D341iSsTEL2i",
        "outputId": "5c901f0e-0efd-43b8-ab25-ed4987d25b9a"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run'], ['thanks', 'lyft', 'credit', \"can't\", 'use', 'cause', 'offer', 'wheelchair', 'vans', 'pdx', 'disapointed', 'getthanked'], ['bihday', 'majesty'], ['model', 'love', 'take', 'time', 'urð'], ['factsguide', 'society', 'motivation']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeh28H2jJZh"
      },
      "source": [
        "#**Check out the top terms in the tweets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "yruksoKFjJZi"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A Counter** is a dict subclass for counting hashable objects. It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values."
      ],
      "metadata": {
        "id": "n-AP7ktwz8Z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's print the top 10 terms in the tweet by creating an empty list and then using forloop and extend method.Then we can count the occurance of each terms in the tweet by passing the list in Counter subclass ."
      ],
      "metadata": {
        "id": "41BYFbNnz-hv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ey4NKg4ujJZi"
      },
      "outputs": [],
      "source": [
        "term_list = []\n",
        "for tweet in tweets_clean:\n",
        "    term_list.extend(tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay009IaXjJZi",
        "outputId": "1756ff6e-6f75-4a11-a06d-9e8a3e98fc18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('love', 2748),\n",
              " ('day', 2276),\n",
              " ('happy', 1684),\n",
              " ('time', 1131),\n",
              " ('life', 1118),\n",
              " ('like', 1047),\n",
              " (\"i'm\", 1018),\n",
              " ('today', 1013),\n",
              " ('new', 994),\n",
              " ('thankful', 946)]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "res = Counter(term_list)\n",
        "res.most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnXnEqb3jJZi"
      },
      "source": [
        "#**Data formatting for predictive modelling** \n",
        "Join the tokens back into strings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4JK6XvDjJZi",
        "outputId": "07bb4e83-3c22-41c0-b5d9-18ed332292a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run']"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ],
      "source": [
        "tweets_clean[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's format the data back to string using join function.So that we can join the empty spaces and convert it to a string."
      ],
      "metadata": {
        "id": "NCtqNcZF0yzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "DGHEWWijjJZi"
      },
      "outputs": [],
      "source": [
        "tweets_clean = [\" \".join(tweet) for tweet in tweets_clean]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's print a sample"
      ],
      "metadata": {
        "id": "a6kAHx8iJQzd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "68RmT3PPjJZi",
        "outputId": "87d8f33d-340c-4364-e812-b56fa61aca5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'never chance vote presidential candidate excited cycle looks different'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ],
      "source": [
        "tweets_clean[30]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8adcBugzjJZj"
      },
      "source": [
        "#**Separate X and Y and perform train test split, 70-30**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's print the length of the tweets and the labels to check whether we have any missing terms."
      ],
      "metadata": {
        "id": "ka9SCVud1fZ9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX2Q3QosjJZj",
        "outputId": "f66e4168-573c-45d7-a936-bb54f8db0cb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31962"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ],
      "source": [
        "len(tweets_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX_OWeiyjJZj",
        "outputId": "08c0842d-b45f-47fb-f1b8-977cc9c0184e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31962"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "len(inp_tweets0.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to use the **train_test_split()** method to split our data into train and test sets. \n",
        "\n",
        "First, we need to divide our data into features (X) and labels (y).\n",
        "\n",
        "Then we can divide our dataset into X_train, X_test, y_train, and y_test. \n",
        "\n",
        "Here,X_train and y_train sets are used for training and fitting the model."
      ],
      "metadata": {
        "id": "FOFcjLll2D8i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, Splitting the data into dependent and independent variable to make predictions."
      ],
      "metadata": {
        "id": "VnXdmhfc1tDh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "Rnx9c8ftjJZj"
      },
      "outputs": [],
      "source": [
        "X = tweets_clean\n",
        "y = inp_tweets0.label.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3w6ivbDjJZj"
      },
      "source": [
        "# Train Test  split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now splitting the whole dataset into testing and training set"
      ],
      "metadata": {
        "id": "O46cps1X13dm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "sxx2U8ZEjJZj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.30, random_state=42 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC7mxrkGjJZj"
      },
      "source": [
        "#**Create a document term matrix using vectorizer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TF-IDF** is a popular approach used to weigh terms for NLP tasks because it assigns a value to a term according to its importance in a document scaled by its importance across all documents in your corpus, which mathematically eliminates naturally occurring words in the English language, and selects words that are more descriptive of your text."
      ],
      "metadata": {
        "id": "PAdnvxhu2iNJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "yeoOaGamjJZj"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here,The purpose of max_features is to limit the number of features (words) from the dataset for which we want to calculate the TF-IDF scores. We are taking a maximum of 5000 features to create the vectorizer"
      ],
      "metadata": {
        "id": "9aMR27rQJvQW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "HgMu8itHjJZk"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px6gxUjFjJZk",
        "outputId": "a042e45a-8dcf-4329-a593-0197fa4a3d01"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22373, 9589)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "len(X_train), len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "YNRrPGpcjJZk"
      },
      "outputs": [],
      "source": [
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_test_bow = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0GAr_A8jJZk",
        "outputId": "33e2936d-3316-4639-b51c-25e230306d42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((22373, 5000), (9589, 5000))"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "X_train_bow.shape, X_test_bow.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIJr36x7jJZk"
      },
      "source": [
        "#**Model building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JokohOxmjJZk"
      },
      "source": [
        "#**Using a simple Logistic Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's use a simpl logistic regression which is used to calculate or predict the probability of a binary (yes/no) event occurring\n"
      ],
      "metadata": {
        "id": "HrYXkJwi2-qn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "YyI76KRYjJZl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "O1PucG7VjJZl"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayI19-bjjJZl",
        "outputId": "7b315a3f-03d9-4449-eb73-bcdde2cd2ed2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ],
      "source": [
        "logreg.fit(X_train_bow, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "5hNiKZP8jJZl"
      },
      "outputs": [],
      "source": [
        "y_train_pred = logreg.predict(X_train_bow)\n",
        "y_test_pred = logreg.predict(X_test_bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's find the performance of our model by finding evaluation metrices like accuracy_score and classification_report.\n",
        "\n"
      ],
      "metadata": {
        "id": "nVHD1pLq5D4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "OSSU5OigjJZl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy** is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right. Formally, accuracy has the following definition: Accuracy = Number of correct predictions divided by Total number of predictions.\n",
        "\n",
        "A **classification report** is a performance evaluation metric in machine learning. It is used to show the precision, recall, F1 Score, and support of your trained classification model.\n",
        "\n"
      ],
      "metadata": {
        "id": "9m7DxcxN6m9r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jPVv7ZPjJZl",
        "outputId": "1c4d28cb-0ef2-4d34-b51f-64fd08db80fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9560184150538595"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "accuracy_score(y_train, y_train_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thus we got a accuracy of **95%**"
      ],
      "metadata": {
        "id": "7I_c11Nh63nF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz3NeniljJZl",
        "outputId": "222b716a-7cba-45fd-9222-940d3103601e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98     20815\n",
            "           1       0.96      0.39      0.55      1558\n",
            "\n",
            "    accuracy                           0.96     22373\n",
            "   macro avg       0.96      0.69      0.76     22373\n",
            "weighted avg       0.96      0.96      0.95     22373\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see that the total number of a class of data (positive) is far less than the total number of another class of data (negative) which implies that our dataset has skewed class proportions."
      ],
      "metadata": {
        "id": "fkH63BK188EM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVufELZjjJZm"
      },
      "source": [
        "#**Adjusting for class imbalance**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to adjust the imbalance class, we have added the class_weight parameter to our logistic regression algorithm and the value we have passed is ‘balanced’ and then we just fit the model to our data."
      ],
      "metadata": {
        "id": "-1bgr8QB8A3Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "NiIFtkVwjJZm"
      },
      "outputs": [],
      "source": [
        "logreg = LogisticRegression(class_weight=\"balanced\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK512F95jJZm",
        "outputId": "739d4fab-ee26-4eb1-9805-34fee8c05ca8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced')"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "logreg.fit(X_train_bow, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "gTJ_7fgJjJZm"
      },
      "outputs": [],
      "source": [
        "y_train_pred = logreg.predict(X_train_bow)\n",
        "y_test_pred = logreg.predict(X_test_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyTg8XHZjJZm",
        "outputId": "2c16b81f-7614-47e1-a353-4781d2fe0072"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9527108568363652"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "accuracy_score(y_train, y_train_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMGBqqSvjJZm",
        "outputId": "a11ed742-8f6a-4bd9-e843-c519556f04b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.95      0.97     20815\n",
            "           1       0.60      0.97      0.74      1558\n",
            "\n",
            "    accuracy                           0.95     22373\n",
            "   macro avg       0.80      0.96      0.86     22373\n",
            "weighted avg       0.97      0.95      0.96     22373\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "2gob-hSf9Z92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV** is a technique for finding the optimal parameter values from a given set of parameters in a grid. It's essentially a cross-validation technique. The model as well as the parameters must be entered. After extracting the best parameter values, predictions are made.\n",
        "\n",
        "**StratifiedKFold** is a cross-validator that divides the dataset into k folds and ensures that each fold of dataset has the same proportion of observations with a given label. We can use this while dealing with classification tasks with imbalanced class distributions\n",
        "\n"
      ],
      "metadata": {
        "id": "-y45lhtA9gHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "cXEShyJ3jJZm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating the parameter grid based on the results of random search"
      ],
      "metadata": {
        "id": "d8Hyr9oS-cuS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "FPhS-j45jJZn"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'C':[0.01,0.1,1,10]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "NIfhZUxvjJZn"
      },
      "outputs": [],
      "source": [
        "classifier_lr = LogisticRegression(class_weight=\"balanced\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's instantiate the grid search model specifying all the parameter values."
      ],
      "metadata": {
        "id": "pn-JeLk7-jrp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "XT3vtPlpjJZn"
      },
      "outputs": [],
      "source": [
        "grid_search = GridSearchCV(estimator = classifier_lr, \n",
        "                           param_grid = param_grid,\n",
        "                          cv=StratifiedKFold(4),\n",
        "                          n_jobs = -1, verbose = 1,\n",
        "                          scoring = \"recall\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ec_t1W9jJZn",
        "outputId": "a6df5c1c-8d74-4791-9b78-b15c2cf96dd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 4 folds for each of 4 candidates, totalling 16 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
              "             estimator=LogisticRegression(class_weight='balanced'), n_jobs=-1,\n",
              "             param_grid={'C': [0.01, 0.1, 1, 10]}, scoring='recall', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ],
      "source": [
        "grid_search.fit(X_train_bow, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding the best estimator ."
      ],
      "metadata": {
        "id": "NquwOMLR-51B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fcq8in9jJZn",
        "outputId": "63df6e24-68cf-44b9-a317-9343abd12580"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1, class_weight='balanced')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "source": [
        "grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgwFds6jJZn"
      },
      "source": [
        "# **Using the best estimator to make predictions on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "R5BNsLCkjJZn"
      },
      "outputs": [],
      "source": [
        "y_test_pred = grid_search.best_estimator_.predict(X_test_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "T4w87tY4jJZn"
      },
      "outputs": [],
      "source": [
        "y_train_pred = grid_search.best_estimator_.predict(X_train_bow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGpRiZDOjJZo",
        "outputId": "e94e9448-62ce-4931-f472-7fc45dfa3d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96      8905\n",
            "           1       0.49      0.77      0.60       684\n",
            "\n",
            "    accuracy                           0.93      9589\n",
            "   macro avg       0.73      0.85      0.78      9589\n",
            "weighted avg       0.95      0.93      0.93      9589\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_test_pred))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}